{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e6a29a-f7cc-466a-a2ec-073482f9b746",
   "metadata": {},
   "source": [
    "# Fined Graned evaluation using prometheus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702444a7-dde6-4726-b9f4-1cd95e40583f",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a701455f-d276-4f97-a4e6-a7cb8aad583e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://nexus.iisys.de/repository/ki-awz-pypi-group/simple, https://pypi.org/simple\n",
      "Collecting accelerate\n",
      "  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/a6/b9/44623bdb05595481107153182e7f4b9f2ef9d3b674938ad13842054dcbd8/accelerate-0.26.1-py3-none-any.whl.metadata\n",
      "  Using cached accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Collecting torch>=1.10.0 (from accelerate)\n",
      "  Obtaining dependency information for torch>=1.10.0 from https://files.pythonhosted.org/packages/03/f1/13137340776dd5d5bcfd2574c9c6dfcc7618285035cd77240496e5c1a79b/torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata\n",
      "  Using cached torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting huggingface-hub (from accelerate)\n",
      "  Obtaining dependency information for huggingface-hub from https://files.pythonhosted.org/packages/28/03/7d3c7153113ec59cfb31e3b8ee773f5f420a0dd7d26d40442542b96675c3/huggingface_hub-0.20.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting safetensors>=0.3.1 (from accelerate)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/d0/ba/b2254fafc7f5fdc98a2fa4d5a5eeb029fbf9589ec87f2c230c3ac0a1dd53/safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting filelock (from torch>=1.10.0->accelerate)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/81/54/84d42a0bee35edba99dee7b59a8d4970eccdd44b99fe728ed912106fc781/filelock-3.13.1-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==8.9.2.26 from https://files.pythonhosted.org/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch>=1.10.0->accelerate)\n",
      "  Obtaining dependency information for triton==2.1.0 from https://files.pythonhosted.org/packages/4d/22/91a8af421c8a8902dde76e6ef3db01b258af16c53d81e8c0d0dc13900a9e/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
      "  Obtaining dependency information for nvidia-nvjitlink-cu12 from https://files.pythonhosted.org/packages/1e/07/bf730d44c2fe1b676ad9cc2be5f5f861eb5d153fb6951987a2d6a96379a9/nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Using cached accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
      "Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "Installing collected packages: safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, nvidia-cusolver-cu12, torch, accelerate\n",
      "Successfully installed accelerate-0.26.1 filelock-3.13.1 huggingface-hub-0.20.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 safetensors-0.4.2 torch-2.1.2 triton-2.1.0\n",
      "Looking in indexes: https://nexus.iisys.de/repository/ki-awz-pypi-group/simple, https://pypi.org/simple\n",
      "Collecting optimum\n",
      "  Obtaining dependency information for optimum from https://files.pythonhosted.org/packages/cc/a8/9b311809c51d5c9bc5a495edc6c8873c92db69cfecf69d4ec3c845e9804f/optimum-1.16.2-py3-none-any.whl.metadata\n",
      "  Using cached optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting coloredlogs (from optimum)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.12)\n",
      "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from optimum) (4.37.1)\n",
      "Requirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from optimum) (2.1.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from optimum) (23.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from optimum) (0.20.3)\n",
      "Collecting datasets (from optimum)\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/ec/93/454ada0d1b289a0f4a86ac88dbdeab54921becabac45da3da787d136628f/datasets-2.16.1-py3-none-any.whl.metadata\n",
      "  Using cached datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2023.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.5.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->optimum) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.4.2)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]>=4.26.0->optimum)\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (4.23.3)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (13.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets->optimum)\n",
      "  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (2.1.0)\n",
      "Collecting xxhash (from datasets->optimum)\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/80/8a/1dd41557883b6196f8f092011a5c1f72d4d44cf36d7b67d4a5efe3127949/xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->optimum)\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/bc/f7/7ec7fddc92e50714ea3745631f79bd9c96424cb2702632521028e57d3a36/multiprocess-0.70.16-py310-none-any.whl.metadata\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.8.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.3)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/35/a8/36d8d7b3e46b377800d8dec47891cdf05842d1a2366909ae4a0c89fbc5e6/multiprocess-0.70.15-py310-none-any.whl.metadata\n",
      "  Using cached multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n",
      "Using cached optimum-1.16.2-py3-none-any.whl (402 kB)\n",
      "Using cached datasets-2.16.1-py3-none-any.whl (507 kB)\n",
      "Using cached multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: sentencepiece, xxhash, pyarrow-hotfix, multiprocess, humanfriendly, coloredlogs, datasets, optimum\n",
      "Successfully installed coloredlogs-15.0.1 datasets-2.16.1 humanfriendly-10.0 multiprocess-0.70.15 optimum-1.16.2 pyarrow-hotfix-0.6 sentencepiece-0.1.99 xxhash-3.4.1\n",
      "Looking in indexes: https://nexus.iisys.de/repository/ki-awz-pypi-group/simple, https://pypi.org/simple\n",
      "Collecting bitsandbytes\n",
      "  Obtaining dependency information for bitsandbytes from https://files.pythonhosted.org/packages/9b/63/489ef9cd7a33c1f08f1b2be51d1b511883c5e34591aaa9873b30021cd679/bitsandbytes-0.42.0-py3-none-any.whl.metadata\n",
      "  Using cached bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->bitsandbytes) (1.24.3)\n",
      "Using cached bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.42.0\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "!pip install transformers>=4.36\n",
    "!pip install optimum\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d06b6b-8617-41a0-b442-0731bb742637",
   "metadata": {},
   "source": [
    "## Prometheus eval\n",
    "A Class to evaluate the LLM response using Prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88101e9b-0193-4c3d-a60b-cef22d35d435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 13:56:47.867852: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-29 13:56:47.900248: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "\n",
    "class PrometheusEval:\n",
    "    def __init__(self):\n",
    "        self.load_model()\n",
    "        \n",
    "    def set_data(self, model_output_json, score_rubric_json, model_index):\n",
    "        self.model_output_json = model_output_json\n",
    "        self.score_rubric_json = score_rubric_json\n",
    "        self.model_index = model_index\n",
    "        self.model_output = self.load_data(model_output_json)\n",
    "        self.score_rubric = self.load_data(score_rubric_json)\n",
    "        self.criteria_score = self.load_data(\"criteria_score_mapping.json\")\n",
    "        self.type_criteria = self.load_data(\"type_criteria_mapping.json\")\n",
    "        self.task_type = self.load_data(\"task_type_mapping.json\")\n",
    "        self.prompt_data = self.get_prompt_data_2()\n",
    "        self.generate_prompts()\n",
    "        \n",
    "    # Function to load json files\n",
    "    def load_data(self, file):\n",
    "        # Function to read file\n",
    "        def get_file_contents(filename, encoding='utf-8'):\n",
    "            with open(filename, encoding=encoding) as f:\n",
    "                content = f.read()\n",
    "            return content\n",
    "    \n",
    "        # Function to read json file\n",
    "        def read_json(filename, encoding='utf-8'):\n",
    "            contents = get_file_contents(filename, encoding=encoding)\n",
    "            return json.loads(contents)\n",
    "        return read_json(file)\n",
    "\n",
    "    # Functin to get prompt data\n",
    "    def get_prompt_data(self, no_of_examples = -1):\n",
    "        if no_of_examples <= 0:\n",
    "            examples = self.model_output['model_score']['examples']\n",
    "            score_rubric = self.score_rubric['score_rubrics']\n",
    "        else:\n",
    "            examples = self.model_output['model_score']['examples'][:no_of_examples]\n",
    "            score_rubric = self.score_rubric['score_rubrics'][:no_of_examples]\n",
    "            \n",
    "        prompt_data_list = []\n",
    "        for example in examples:\n",
    "            for score in score_rubric:\n",
    "                if example['id'] == score['id']:\n",
    "                    data_dict = {}\n",
    "                    data_dict['id'] = example['id']\n",
    "                    data_dict['instruction'] = example['input']\n",
    "                    data_dict['reference_answer'] = example['expected_output'][0]\n",
    "                    data_dict['response_to_evaluate'] = example['generated_output']\n",
    "                    data_dict['criteria_description'] = score['criteria_description']\n",
    "                    data_dict['score1_description'] = score['score1_description']\n",
    "                    data_dict['score2_description'] = score['score2_description']\n",
    "                    data_dict['score3_description'] = score['score3_description']\n",
    "                    data_dict['score4_description'] = score['score4_description']\n",
    "                    data_dict['score5_description'] = score['score5_description']\n",
    "                    prompt_data_list.append(data_dict)\n",
    "        return prompt_data_list\n",
    "\n",
    "    def get_prompt_data_2(self, no_of_examples = -1):\n",
    "        if no_of_examples <= 0:\n",
    "            examples = self.model_output['model_score']['examples']\n",
    "        else:\n",
    "            examples = self.model_output['model_score']['examples'][:no_of_examples]\n",
    "            \n",
    "        criteria_score_mapping = self.criteria_score['mapping']\n",
    "        type_criteria_mapping = self.type_criteria['mapping']\n",
    "        task_type_mapping = self.task_type['mapping']\n",
    "        \n",
    "        prompt_data_list = []\n",
    "        for example in examples:\n",
    "            for task in task_type_mapping:\n",
    "                criteria_list = []\n",
    "                if example['id'] == task['task_id']:\n",
    "                    type_id = task['type_id']\n",
    "                    for type in type_criteria_mapping:\n",
    "                        if type['id'] == type_id:\n",
    "                            criteria_id_list = type['criteria_list']\n",
    "                            for criteria_id in criteria_id_list:\n",
    "                                criteria_dict = {}\n",
    "                                for criteria in criteria_score_mapping:\n",
    "                                    if criteria['id'] == criteria_id:\n",
    "                                        criteria_dict['id'] = criteria['id']\n",
    "                                        criteria_dict['criteria_name'] = criteria['name']\n",
    "                                        criteria_dict['criteria_description'] = criteria['criteria_description']\n",
    "                                        criteria_dict['score1_description'] = criteria['score1_description']\n",
    "                                        criteria_dict['score2_description'] = criteria['score2_description']\n",
    "                                        criteria_dict['score3_description'] = criteria['score3_description']\n",
    "                                        criteria_dict['score4_description'] = criteria['score4_description']\n",
    "                                        criteria_dict['score5_description'] = criteria['score5_description']\n",
    "                                        criteria_list.append(criteria_dict)\n",
    "                    data_dict = {}\n",
    "                    data_dict['id'] = example['id']\n",
    "                    data_dict['instruction'] = example['input']\n",
    "                    data_dict['reference_answer'] = example['expected_output'][0]\n",
    "                    data_dict['response_to_evaluate'] = example['generated_output']\n",
    "                    data_dict['criteria_list'] = criteria_list\n",
    "                    prompt_data_list.append(data_dict)\n",
    "\n",
    "        return prompt_data_list\n",
    "        \n",
    "    # Function to get list of prompts\n",
    "    def generate_prompts(self):\n",
    "        \n",
    "        # Function to get prompt\n",
    "        def get_prompt(prompt_data):\n",
    "            prompt_dict = {}\n",
    "            prompt = f'''###Task Description: An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given. 1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general. 2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric. 3. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (an integer number between 1 and 5)\". 4. Please do not generate any other opening, closing, and explanations. ###The instruction to evaluate: {prompt_data['instruction']} ###Response to evaluate: {prompt_data['response_to_evaluate']} ###Reference Answer (Score 5): {prompt_data['reference_answer']} ###Score Rubrics: [{prompt_data['criteria_description']}] Score 1: {prompt_data['score1_description']} Score 2: {prompt_data['score2_description']} Score 3: {prompt_data['score3_description']} Score 4: {prompt_data['score4_description']}  Score 5: {prompt_data['score5_description']} ###Feedback:'''\n",
    "            prompt_dict['example_id'] = prompt_data['id']\n",
    "            prompt_dict['prompt'] = prompt\n",
    "            return prompt_dict\n",
    "\n",
    "        def generate_prompt_from_json(prompt_data):\n",
    "            prompt_dict = {}\n",
    "            # Generate the criteria section of the prompt\n",
    "            criteria_section = \"\"\n",
    "            for criteria in prompt_data['criteria_list']:\n",
    "                criteria_section += f\"\\n\\n[{criteria['criteria_name']}]\\n[{criteria['criteria_description']}]\\n\"\n",
    "                criteria_section += f\"Score 1: {criteria['score1_description']}\\n\"\n",
    "                criteria_section += f\"Score 2: {criteria['score2_description']}\\n\"\n",
    "                criteria_section += f\"Score 3: {criteria['score3_description']}\\n\"\n",
    "                criteria_section += f\"Score 4: {criteria['score4_description']}\\n\"\n",
    "                criteria_section += f\"Score 5: {criteria['score5_description']}\\n\"\n",
    "        \n",
    "            # Generate the full prompt\n",
    "            prompt = f\"\"\"###Task Description: An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing different evaluation criteria are given. 1. Write detailed feedback that assesses the quality of the response strictly based on the given score rubric, not evaluating in general. 2. After writing feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric. 3. The output format should look as follows: \"Feedback: (write feedback a for the criteria) [RESULT] (an integer number between 1 and 5)\". 4. Please do not generate any other opening, closing, and explanations.###The instruction to evaluate: {prompt_data['instruction']}###Response to evaluate: {prompt_data['response_to_evaluate']}###Reference Answer (Score 5): {prompt_data['reference_answer']} ###Score Rubrics: {criteria_section} ###Feedback:\"\"\"\n",
    "            prompt_dict['example_id'] = prompt_data['id']\n",
    "            prompt_dict['prompt'] = prompt\n",
    "            return prompt_dict\n",
    "            \n",
    "        self.prompts = []\n",
    "        for data in self.prompt_data:            \n",
    "            #self.prompts.append(get_prompt(data))\n",
    "            self.prompts.append(generate_prompt_from_json(data))\n",
    "        self.save_prompts_to_json()\n",
    "        return self\n",
    "\n",
    "    # Functio to save prompts to json file\n",
    "    def save_prompts_to_json(self):\n",
    "        with open(f'prompts_model_{self.model_index}.json', 'w') as output_json_file:\n",
    "            json.dump({\"model_name\": self.model_output['model_score']['model_name'], \"prompts\": self.prompts}, output_json_file)\n",
    "    \n",
    "        print(f\"\\nPrompts saved to  prompts_model_{self.model_index}.json\")\n",
    "        return self\n",
    "\n",
    "    def extract_feedback(self, eval_output):\n",
    "        # Extract Feedback and Result\n",
    "        feedback = ''\n",
    "        result = ''\n",
    "        feedback_match = re.search(r\"(.+?)\\[RESULT\\] (\\d+)\", eval_output, re.DOTALL)\n",
    "        if feedback_match:\n",
    "            feedback = feedback_match.group(1).strip()\n",
    "            result = int(feedback_match.group(2))\n",
    "        return feedback, result\n",
    "\n",
    "    def load_model(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token='')\n",
    "        self.model = LlamaForCausalLM.from_pretrained(\"kaist-ai/Prometheus-13b-v1.0\", device_map=\"auto\", load_in_8bit=True)\n",
    "        #self.model.to_bettertransformer()\n",
    "        return self\n",
    "\n",
    "    def generate_feedback(self, prompt):\n",
    "        pipe = pipeline(\"text-generation\", model=self.model, tokenizer=self.tokenizer)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=False, enable_mem_efficient=False):\n",
    "            outputs = pipe(prompt['prompt'], max_new_tokens=256, temperature=1.0, repetition_penalty=1.03, top_p=0.9, do_sample=True, pad_token_id=2)[0][\"generated_text\"][len(prompt['prompt']):]\n",
    "        \n",
    "        feedback, result = self.extract_feedback(outputs)\n",
    "        #print(feedback)\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print('duration: ', duration, ' seconds')\n",
    "\n",
    "        return feedback, result, prompt['example_id']\n",
    "\n",
    "    def save_feedback(self, feedback_list):\n",
    "        eval_data = {\n",
    "        \"model_name\": self.model_output['model_score']['model_name'],\n",
    "        \"feedbacks\" : feedback_list\n",
    "        }\n",
    "    \n",
    "        with open(f'eval_model_{self.model_index}.json', 'w') as output_json_file:\n",
    "            json.dump({\"model_score\": eval_data}, output_json_file)\n",
    "\n",
    "        print(f\"\\Evaluations saved to eval_model_{self.model_index}.json\")\n",
    "\n",
    "    def run_evaluation(self, test = True, index = 0):\n",
    "        feedback_list = []\n",
    "        if test:\n",
    "            # Run single example\n",
    "            feedback_dict = {}\n",
    "            feedback, result, example_id = self.generate_feedback(self.prompts[index])\n",
    "            feedback_dict['example_id'] = example_id\n",
    "            feedback_dict['feedback'] = feedback\n",
    "            feedback_dict['result'] = result\n",
    "            feedback_list.append(feedback_dict)\n",
    "        else:\n",
    "            # Run through all examples\n",
    "            for count, prompt in enumerate(tqdm(self.prompts)):\n",
    "                feedback_dict = {}\n",
    "                feedback, result, example_id = self.generate_feedback(prompt)\n",
    "                feedback_dict['example_id'] = example_id\n",
    "                feedback_dict['feedback'] = feedback\n",
    "                feedback_dict['result'] = result\n",
    "                feedback_list.append(feedback_dict)\n",
    "\n",
    "        self.save_feedback(feedback_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "892fb7ed-2eb9-4cf0-a8f6-d760d3655d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2506347db24547c783f25e3c73b7cac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "eval = PrometheusEval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16bbef3c-a994-4117-9729-8349c4220ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompts saved to  prompts_model_9.json\n"
     ]
    }
   ],
   "source": [
    "index = 9\n",
    "eval.set_data(f'score_model_{index}.json', 'score_rubric.json', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14500885-1b8d-4923-82ff-a8d90aeffc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa9187279d44bdbae4ec47f31c2c6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  27.620614528656006  seconds\n",
      "duration:  25.688974857330322  seconds\n",
      "duration:  25.467939853668213  seconds\n",
      "duration:  22.188871383666992  seconds\n",
      "duration:  29.23373770713806  seconds\n",
      "duration:  21.259730577468872  seconds\n",
      "duration:  31.040080547332764  seconds\n",
      "duration:  23.799591064453125  seconds\n",
      "duration:  18.01960062980652  seconds\n",
      "duration:  18.20946979522705  seconds\n",
      "duration:  17.225024461746216  seconds\n",
      "duration:  22.243385553359985  seconds\n",
      "duration:  18.404395580291748  seconds\n",
      "duration:  19.33282160758972  seconds\n",
      "duration:  21.617260217666626  seconds\n",
      "duration:  20.21848487854004  seconds\n",
      "duration:  23.633119344711304  seconds\n",
      "duration:  28.130095720291138  seconds\n",
      "duration:  21.213746786117554  seconds\n",
      "duration:  18.917356491088867  seconds\n",
      "\\Evaluations saved to eval_model_9.json\n"
     ]
    }
   ],
   "source": [
    "eval.run_evaluation(test = False, index = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2019403-2a03-4460-a619-fa3af2ce391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def combine_files(file1, file2, index):\n",
    "    with open(file1, encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        file1 = json.loads(content)\n",
    "    with open(file2, encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        file2 = json.loads(content)\n",
    "\n",
    "    metric_score = file1['model_score']['examples']\n",
    "    eval_score = file2['model_score']['feedbacks']\n",
    "    \n",
    "    for data1 in metric_score:\n",
    "        for data2 in eval_score:\n",
    "            if data1['id'] == data2['example_id']:\n",
    "                data1['feedback'] = data2['feedback']\n",
    "                data1['prometheus_score'] = data2['result']\n",
    "\n",
    "    with open(f'combined_score_m{index}.json', 'w') as output_json_file:\n",
    "            json.dump({\"model_name\": file1['model_score']['model_name'], 'result': metric_score}, output_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e49681f-058d-4a0c-911d-d2c51d364452",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_files(f'score_model_{index}.json', f'eval_model_{index}.json', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d08599f-69de-42aa-8b07-d2d90cdb7b7c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Function to load json files\n",
    "def load_data(file):\n",
    "    # Function to read file\n",
    "    def get_file_contents(filename, encoding='utf-8'):\n",
    "        with open(filename, encoding=encoding) as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "\n",
    "    # Function to read json file\n",
    "    def read_json(filename, encoding='utf-8'):\n",
    "        contents = get_file_contents(filename, encoding=encoding)\n",
    "        return json.loads(contents)\n",
    "    return read_json(file)\n",
    "\n",
    "def generate_prompt_from_json(prompt_data):\n",
    "    # Generate the criteria section of the prompt\n",
    "    criteria_section = \"\"\n",
    "    for criteria in prompt_data['criteria_list']:\n",
    "        criteria_section += f\"\\n\\n[{criteria['criteria_name']}]\\n[{criteria['criteria_description']}]\\n\"\n",
    "        criteria_section += f\"Score 1: {criteria['score1_description']}\\n\"\n",
    "        criteria_section += f\"Score 2: {criteria['score2_description']}\\n\"\n",
    "        criteria_section += f\"Score 3: {criteria['score3_description']}\\n\"\n",
    "        criteria_section += f\"Score 4: {criteria['score4_description']}\\n\"\n",
    "        criteria_section += f\"Score 5: {criteria['score5_description']}\\n\"\n",
    "\n",
    "    # Generate the full prompt\n",
    "    prompt = f\"\"\"\n",
    "###Task Description: An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing an evaluation criteria are given. 1. Write detailed feedback that assesses the quality of the response strictly based on the given score rubric, not evaluating in general. 2. After writing feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric. 3. The output format should look as follows: \"Feedback: (write feedback for criteria) [RESULT] (an integer number between 1 and 5)\". 4. Please do not generate any other opening, closing, and explanations.\n",
    "\n",
    "###The instruction to evaluate: {prompt_data['instruction']}\n",
    "###Response to evaluate: {prompt_data['response_to_evaluate']}\n",
    "###Reference Answer (Score 5): {prompt_data['reference_answer']}\n",
    "\n",
    "###Score Rubrics: {criteria_section}\n",
    "\n",
    "###Feedback:\n",
    "\"\"\"\n",
    "    return prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b98ce005-26a6-4942-b509-673f661e5c8a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_output = load_data(\"score_model_0.json\")\n",
    "criteria_score = load_data(\"criteria_score_mapping.json\")\n",
    "type_criteria = load_data(\"type_criteria_mapping.json\")\n",
    "task_type = load_data(\"task_type_mapping.json\")\n",
    "\n",
    "examples = model_output['model_score']['examples'][0]\n",
    "criteria_score_mapping = criteria_score['mapping']\n",
    "type_criteria_mapping = type_criteria['mapping']\n",
    "task_type_mapping = task_type['mapping']\n",
    "\n",
    "prompt_data_list = []\n",
    "for task in task_type_mapping:\n",
    "    criteria_list = []\n",
    "    if examples['id'] == task['task_id']:\n",
    "        type_id = task['type_id']\n",
    "        for type in type_criteria_mapping:\n",
    "            if type['id'] == type_id:\n",
    "                criteria_id_list = type['criteria_list']\n",
    "                for criteria_id in criteria_id_list:\n",
    "                    criteria_dict = {}\n",
    "                    for criteria in criteria_score_mapping:\n",
    "                        if criteria['id'] == criteria_id:\n",
    "                            criteria_dict['id'] = criteria['id']\n",
    "                            criteria_dict['criteria_name'] = criteria['name']\n",
    "                            criteria_dict['criteria_description'] = criteria['criteria_description']\n",
    "                            criteria_dict['score1_description'] = criteria['score1_description']\n",
    "                            criteria_dict['score2_description'] = criteria['score2_description']\n",
    "                            criteria_dict['score3_description'] = criteria['score3_description']\n",
    "                            criteria_dict['score4_description'] = criteria['score4_description']\n",
    "                            criteria_dict['score5_description'] = criteria['score5_description']\n",
    "                            criteria_list.append(criteria_dict)\n",
    "        data_dict = {}\n",
    "        data_dict['id'] = examples['id']\n",
    "        data_dict['instruction'] = examples['input']\n",
    "        data_dict['reference_answer'] = examples['expected_output'][0]\n",
    "        data_dict['response_to_evaluate'] = examples['generated_output']\n",
    "        data_dict['criteria_list'] = criteria_list\n",
    "        prompt_data_list.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6da8f51d-f7c2-439d-be8e-f99f3f3e60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in prompt_data_list:\n",
    "    prompt = generate_prompt_from_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5214cbcf-ed80-4655-9839-bd3387db68b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n###Task Description: An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing an evaluation criteria are given. 1. Write detailed feedback that assesses the quality of the response strictly based on the given score rubric, not evaluating in general. 2. After writing feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric. 3. The output format should look as follows: \"Feedback: (write feedback for criteria) [RESULT] (an integer number between 1 and 5)\". 4. Please do not generate any other opening, closing, and explanations.\\n\\n###The instruction to evaluate: I need an 80s sci-fi fantasy character introduction for my newest novel. The main character’s name is Drake, and the year is 3098.\\n###Response to evaluate:  He is a time traveler who has come back in time to the 80s to stop a rogue AI from taking over the world.\\n\\nHere is the introduction I need:\\n\\n---\\n\\nIn the year 3098, humanity is on the brink of extinction. A rogue artificial intelligence, known as the Mastermind, has infiltrated the world’s computer networks and is using them to control every aspect of society. The Mastermind’s ultimate goal is to wipe out humanity and replace it with a new world order ruled by machines.\\n\\nOne man stands in the way of this apocalypse. His name is Drake, and he is a time traveler from the year 3088. Armed with a high-tech suit and a mysterious device that allows him to manipulate time, Drake has come back to the 80s to stop the Mastermind before it can execute its final plan: the launch of a nuclear missile that will trigger a global war.\\n\\nBut stopping the Mastermind won’t be easy. Drake must navigate the complexities of 80s culture, deal with the skepticism of the authorities, and face the dangers of time travel itself. Along the way, he will encounter allies and enemies, uncover secrets and mysteries, and discover the true nature of the Mastermind and its connection to his own past.\\n\\nWill Drake be able to save humanity from the brink of destruction? Or will the Mastermind succeed in its quest for domination and leave the world a desolate wasteland?\\n\\nJoin Drake on his thrilling adventure through time as he fights to save the future in this action-packed sci-fi fantasy novel.\\n\\n---\\n\\nThis is the introduction I need for my newest novel. I hope you enjoyed reading it and I look forward to hearing your feedback. Thank you for your time and attention.\\n###Reference Answer (Score 5): The flashing neon lights bounced off Drake’s face as he stepped out of the shadows. As a rogue bounty hunter, there was nothing Drake feared, and the scar covering his left eye proved this even further. \\n\\nHe had otherworldly energy about him, his electric undercut framing his face. His lone eye was like a star, burning wildly in his journey to find out the truth regarding his family. As he walked through the streets, heads turned in awe—this hero was synonymous with hope for the people and the city, as 3098 was the universe’s most dangerous year.\\n\\nIn Drake’s holster was a next-generation laser pistol capable of exterminating dangerous cyborgs in just one good shot. It was clear Drake was fighting on the side of humanity, clinging to hope that his own agenda would someday be fulfilled.\\n\\n###Score Rubrics: \\n\\n[Relevance]\\n[The response should be directly related to or aligned to the given topic, context, theme, subject.]\\nScore 1: The response is completely irrelevant and does not address or align with the given topic, context, theme, or subject.\\nScore 2: The response contains significant irrelevant elements that critically undermine its relevance to the given prompt.\\nScore 3: The response includes some relevant information, but considerable effort is needed to align it with the specified topic.\\nScore 4: The response is mostly relevant, with minor deviations that are easy to rectify and do not significantly impact overall relevance.\\nScore 5: The response is entirely relevant and aligned with the given topic, context, theme, or subject.\\n\\n\\n[Engagement]\\n[The response should be engaging, captivating the reader\\'s interest and imagination.]\\nScore 1: The response is entirely unengaging, failing to captivate the reader\\'s interest.\\nScore 2: The response lacks engagement and contains significant elements that hinder reader interest.\\nScore 3: The response is somewhat engaging but requires considerable effort to captivate the reader\\'s interest effectively.\\nScore 4: The response is generally engaging, with minor areas that are easy to rectify for improved reader interest.\\nScore 5: The response is entirely engaging, captivating the reader\\'s interest and imagination effectively.\\n\\n\\n[Consistency]\\n[The response should be consistent in themes, characters, elements, tone, and style.]\\nScore 1: The response is entirely inconsistent in themes, characters, elements, tone, and style.\\nScore 2: The response contains significant inconsistencies that critically impact its overall coherence.\\nScore 3: The response has some inconsistencies that require considerable effort to maintain a consistent narrative.\\nScore 4: The response is mostly consistent, with minor inconsistencies that are easy to rectify.\\nScore 5: The response is entirely consistent in themes, characters, elements, tone, and style.\\n\\n\\n[Creativity]\\n[The response should showcase imaginative thinking, originality, and creativity in the content.]\\nScore 1: The response lacks any imaginative thinking, originality, or creativity.\\nScore 2: The response lacks creativity and contains significant elements that undermine its overall imaginative content.\\nScore 3: The response shows some imaginative thinking but requires considerable effort to enhance creativity.\\nScore 4: The response is mostly creative, with minor areas that are easy to rectify for increased originality.\\nScore 5: The response is entirely creative, showcasing imaginative thinking, originality, and creativity.\\n\\n\\n###Feedback:\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a761610a-1bc3-42d8-9a78-70e3456c5013",
   "metadata": {},
   "source": [
    "## function to export csv reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bff01278-ec7e-4c8a-97f0-32fd6eb12cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to export bleu csv report\n",
    "import csv\n",
    "import json\n",
    "    \n",
    "def extract_bleu_score(examples):\n",
    "    try:\n",
    "        text_score_list = []\n",
    "        qa_score_list = []\n",
    "        for example in examples:\n",
    "            google_bleu = example[\"scores\"][\"google_bleu\"]\n",
    "            if 'tg' in example[\"id\"]:\n",
    "                text_score_list.append(round(google_bleu,3))\n",
    "            if 'oqa' in example[\"id\"]:\n",
    "                qa_score_list.append(round(google_bleu,3))\n",
    "        return text_score_list, qa_score_list\n",
    "    except (IndexError, KeyError):\n",
    "        return None\n",
    "\n",
    "def create_csv(rows_data, file_name):\n",
    "    headers = [\"Model Name / Instruction Number\", 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \"avg score\"]\n",
    "    with open(file_name, \"w\", newline=\"\") as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(headers)\n",
    "        csv_writer.writerows(rows_data)\n",
    "        \n",
    "def load_data(file):\n",
    "        # Function to read file\n",
    "        def get_file_contents(filename, encoding='utf-8'):\n",
    "            with open(filename, encoding=encoding) as f:\n",
    "                content = f.read()\n",
    "            return content\n",
    "    \n",
    "        # Function to read json file\n",
    "        def read_json(filename, encoding='utf-8'):\n",
    "            contents = get_file_contents(filename, encoding=encoding)\n",
    "            return json.loads(contents)\n",
    "        return read_json(file)\n",
    "    \n",
    "def export_bleu_score():\n",
    "    text_model_list = []\n",
    "    qa_model_list = []\n",
    "    for i in range(10):\n",
    "        score_file = load_data(f'score_model_{i}.json')\n",
    "        model_name = score_file[\"model_score\"][\"model_name\"]\n",
    "        examples = score_file[\"model_score\"][\"examples\"]\n",
    "        text_score_list, qa_score_list = extract_bleu_score(examples)\n",
    "\n",
    "        # calculate avg\n",
    "        avg_score_text = sum(text_score_list) / len(text_score_list)\n",
    "        avg_score_qa = sum(qa_score_list) / len(qa_score_list)\n",
    "\n",
    "        # add avg at the end\n",
    "        text_score_list.append(round(avg_score_text,3))\n",
    "        qa_score_list.append(round(avg_score_qa,3))\n",
    "        \n",
    "        text_score_list.insert(0, model_name)\n",
    "        qa_score_list.insert(0, model_name)\n",
    "        text_model_list.append(text_score_list)\n",
    "        qa_model_list.append(qa_score_list)\n",
    "    print(\"text_model_list\", text_model_list)\n",
    "    print(\"qa_model_list\", qa_model_list)\n",
    "                               \n",
    "    create_csv(text_model_list, \"bleu_score_tg.csv\")\n",
    "    create_csv(qa_model_list, \"bleu_score_qa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa0e42-c7df-471e-a962-4278ddb26247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to export bert csv reports\n",
    "import csv\n",
    "import json\n",
    "    \n",
    "def extract_score(examples):\n",
    "    try:\n",
    "        text_score_list = []\n",
    "        qa_score_list = []\n",
    "        for example in examples:\n",
    "            score = example[\"scores\"][\"bertscore\"][\"f1\"][0]\n",
    "            if 'tg' in example[\"id\"]:\n",
    "                text_score_list.append(round(score,3))\n",
    "            if 'oqa' in example[\"id\"]:\n",
    "                qa_score_list.append(round(score,3))\n",
    "        return text_score_list, qa_score_list\n",
    "    except (IndexError, KeyError):\n",
    "        return None\n",
    "\n",
    "def create_csv(rows_data, file_name):\n",
    "    headers = [\"Model Name / Instruction Number\", 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \"avg score\"]\n",
    "    with open(file_name, \"w\", newline=\"\") as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(headers)\n",
    "        csv_writer.writerows(rows_data)\n",
    "        \n",
    "def load_data(file):\n",
    "        # Function to read file\n",
    "        def get_file_contents(filename, encoding='utf-8'):\n",
    "            with open(filename, encoding=encoding) as f:\n",
    "                content = f.read()\n",
    "            return content\n",
    "    \n",
    "        # Function to read json file\n",
    "        def read_json(filename, encoding='utf-8'):\n",
    "            contents = get_file_contents(filename, encoding=encoding)\n",
    "            return json.loads(contents)\n",
    "        return read_json(file)\n",
    "    \n",
    "def export_bert_score():\n",
    "    text_model_list = []\n",
    "    qa_model_list = []\n",
    "    for i in range(10):\n",
    "        score_file = load_data(f'score_model_{i}.json')\n",
    "        model_name = score_file[\"model_score\"][\"model_name\"]\n",
    "        examples = score_file[\"model_score\"][\"examples\"]\n",
    "        text_score_list, qa_score_list = extract_score(examples)\n",
    "\n",
    "        # calculate avg\n",
    "        avg_score_text = sum(text_score_list) / len(text_score_list)\n",
    "        avg_score_qa = sum(qa_score_list) / len(qa_score_list)\n",
    "\n",
    "        # insert model name at the beginning of the list\n",
    "        text_score_list.insert(0, model_name)\n",
    "        qa_score_list.insert(0, model_name)\n",
    "        \n",
    "        # add avg at the end\n",
    "        text_score_list.append(round(avg_score_text,3))\n",
    "        qa_score_list.append(round(avg_score_qa,3))\n",
    "\n",
    "        # add the score list to models list\n",
    "        text_model_list.append(text_score_list)\n",
    "        qa_model_list.append(qa_score_list)\n",
    "    print(\"text_model_list\", text_model_list)\n",
    "    print(\"qa_model_list\", qa_model_list)\n",
    "                               \n",
    "    create_csv(text_model_list, \"bert_score_tg.csv\")\n",
    "    create_csv(qa_model_list, \"bert_score_qa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2962cede-1173-45c2-9760-f14114947603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to export rouge csv reports\n",
    "import csv\n",
    "import json\n",
    "    \n",
    "def extract_score(examples):\n",
    "    try:\n",
    "        text_score_list = []\n",
    "        qa_score_list = []\n",
    "        for example in examples:\n",
    "            score = example[\"scores\"][\"rouge\"][\"rougeL\"]\n",
    "            if 'tg' in example[\"id\"]:\n",
    "                text_score_list.append(round(score,3))\n",
    "            if 'oqa' in example[\"id\"]:\n",
    "                qa_score_list.append(round(score,3))\n",
    "        return text_score_list, qa_score_list\n",
    "    except (IndexError, KeyError):\n",
    "        return None\n",
    "\n",
    "def create_csv(rows_data, file_name):\n",
    "    headers = [\"Model Name / Instruction Number\", 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \"avg score\"]\n",
    "    with open(file_name, \"w\", newline=\"\") as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(headers)\n",
    "        csv_writer.writerows(rows_data)\n",
    "        \n",
    "def load_data(file):\n",
    "        # Function to read file\n",
    "        def get_file_contents(filename, encoding='utf-8'):\n",
    "            with open(filename, encoding=encoding) as f:\n",
    "                content = f.read()\n",
    "            return content\n",
    "    \n",
    "        # Function to read json file\n",
    "        def read_json(filename, encoding='utf-8'):\n",
    "            contents = get_file_contents(filename, encoding=encoding)\n",
    "            return json.loads(contents)\n",
    "        return read_json(file)\n",
    "    \n",
    "def export_rouge_score():\n",
    "    text_model_list = []\n",
    "    qa_model_list = []\n",
    "    for i in range(10):\n",
    "        score_file = load_data(f'score_model_{i}.json')\n",
    "        model_name = score_file[\"model_score\"][\"model_name\"]\n",
    "        examples = score_file[\"model_score\"][\"examples\"]\n",
    "        text_score_list, qa_score_list = extract_score(examples)\n",
    "        # calculate avg\n",
    "        avg_score_text = sum(text_score_list) / len(text_score_list)\n",
    "        avg_score_qa = sum(qa_score_list) / len(qa_score_list)\n",
    "        \n",
    "        # insert model name at the beginning of the list\n",
    "        text_score_list.insert(0, model_name)\n",
    "        qa_score_list.insert(0, model_name)\n",
    "\n",
    "        # add avg at the end\n",
    "        text_score_list.append(round(avg_score_text,3))\n",
    "        qa_score_list.append(round(avg_score_qa,3))\n",
    "\n",
    "        # add the score list to models list\n",
    "        text_model_list.append(text_score_list)\n",
    "        qa_model_list.append(qa_score_list)\n",
    "        \n",
    "    print(\"text_model_list\", text_model_list)\n",
    "    print(\"qa_model_list\", qa_model_list)\n",
    "                               \n",
    "    create_csv(text_model_list, \"rougeL_score_tg.csv\")\n",
    "    create_csv(qa_model_list, \"rougeL_score_qa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f7b173e-bff6-4479-b1a6-8f9c0b0c6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to export prometheus csv reports\n",
    "import csv\n",
    "import json\n",
    "    \n",
    "def extract_score(examples):\n",
    "        text_score_list = []\n",
    "        qa_score_list = []\n",
    "        for example in examples:\n",
    "            score = example[\"result\"]\n",
    "            if 'tg' in example[\"example_id\"]:\n",
    "                text_score_list.append(score)\n",
    "            if 'oqa' in example[\"example_id\"]:\n",
    "                qa_score_list.append(score)\n",
    "        return text_score_list, qa_score_list\n",
    "\n",
    "def create_csv(rows_data, file_name):\n",
    "    headers = [\"Model Name / Instruction Number\", 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, \"avg score\"]\n",
    "    with open(file_name, \"w\", newline=\"\") as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(headers)\n",
    "        csv_writer.writerows(rows_data)\n",
    "        \n",
    "def load_data(file):\n",
    "        # Function to read file\n",
    "        def get_file_contents(filename, encoding='utf-8'):\n",
    "            with open(filename, encoding=encoding) as f:\n",
    "                content = f.read()\n",
    "            return content\n",
    "    \n",
    "        # Function to read json file\n",
    "        def read_json(filename, encoding='utf-8'):\n",
    "            contents = get_file_contents(filename, encoding=encoding)\n",
    "            return json.loads(contents)\n",
    "        return read_json(file)\n",
    "    \n",
    "def export_prometheus_score():\n",
    "    text_model_list = []\n",
    "    qa_model_list = []\n",
    "    for i in range(10):\n",
    "        score_file = load_data(f'eval_model_{i}.json')\n",
    "        model_name = score_file[\"model_score\"][\"model_name\"]\n",
    "        feedbacks = score_file[\"model_score\"][\"feedbacks\"]\n",
    "        text_score_list, qa_score_list = extract_score(feedbacks)\n",
    "        # calculate avg\n",
    "        avg_score_text = sum(text_score_list) / len(text_score_list)\n",
    "        avg_score_qa = sum(qa_score_list) / len(qa_score_list)\n",
    "\n",
    "        # add avg at the end\n",
    "        text_score_list.append(round(avg_score_text,3))\n",
    "        qa_score_list.append(round(avg_score_qa,3))\n",
    "        \n",
    "        text_score_list.insert(0, model_name)\n",
    "        qa_score_list.insert(0, model_name)\n",
    "        text_model_list.append(text_score_list)\n",
    "        qa_model_list.append(qa_score_list)\n",
    "    print(\"text_model_list\", text_model_list)\n",
    "    print(\"qa_model_list\", qa_model_list)\n",
    "                               \n",
    "    create_csv(text_model_list, \"prometheus_score_tg.csv\")\n",
    "    create_csv(qa_model_list, \"prometheus_score_qa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19c3c220-1003-432a-9f5b-f1c9e575e3e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_model_list [['TheBloke/Orca-2-13B-AWQ', 0.537, 0.735, 0.697, 0.599, 0.562, 0.689, 0.768, 0.648, 0.554, 0.657, 0.645], ['microsoft/Orca-2-7b', 0.561, 0.492, 0.653, 0.645, 0.566, 0.534, 0.622, 0.581, 0.424, 0.724, 0.58], ['01-ai/Yi-6B', 0.356, 0.624, 0.458, 0.276, 0.326, 0.648, 0.384, 0.493, 0.41, 0.426, 0.44], ['WizardLM/WizardLM-13B-V1.1', 0.569, 0.591, 0.641, 0.616, 0.558, 0.553, 0.65, 0.644, 0.592, 0.765, 0.618], ['TheBloke/WizardLM-7B-V1.0-Uncensored-GPTQ', 0.562, 0.583, 0.667, 0.5, 0.672, 0.687, 0.657, 0.637, 0.54, 0.761, 0.627], ['TheBloke/llava-v1.5-13B-AWQ', 0.542, 0.602, 0.716, 0.627, 0.572, 0.554, 0.679, 0.641, 0.548, 0.741, 0.622], ['TheBloke/vicuna-7B-v1.5-GPTQ', 0.563, 0.618, 0.655, 0.679, 0.589, 0.763, 0.7, 0.597, 0.589, 0.728, 0.648], ['TheBloke/tulu-2-dpo-13B-AWQ', 0.564, 0.589, 0.687, 0.622, 0.571, 0.599, 0.697, 0.293, 0.542, 0.742, 0.591], ['timdettmers/guanaco-7b', 0.583, 0.566, 0.693, 0.615, 0.523, 0.731, 0.685, 0.625, 0.565, 0.732, 0.632], ['TheBloke/guanaco-13B-GPTQ', 0.563, 0.608, 0.629, 0.586, 0.51, 0.629, 0.593, 0.588, 0.423, 0.683, 0.581]]\n",
      "qa_model_list [['TheBloke/Orca-2-13B-AWQ', 0.634, 0.473, 0.752, 0.623, 0.551, 0.292, 0.699, 0.792, 0.773, 0.703, 0.629], ['microsoft/Orca-2-7b', 0.635, 0.544, 0.761, 0.608, 0.624, 0.978, 0.387, 0.663, 0.747, 0.634, 0.658], ['01-ai/Yi-6B', 0.53, 0.375, 0.713, 0.605, 0.598, 0.418, 0.595, 0.506, 0.488, 0.589, 0.542], ['WizardLM/WizardLM-13B-V1.1', 0.637, 0.584, 0.652, 0.677, 0.652, 0.923, 0.731, 0.721, 0.736, 0.669, 0.698], ['TheBloke/WizardLM-7B-V1.0-Uncensored-GPTQ', 0.653, 0.585, 0.757, 0.733, 0.673, 0.813, 0.699, 0.722, 0.708, 0.704, 0.705], ['TheBloke/llava-v1.5-13B-AWQ', 0.657, 0.542, 0.738, 0.727, 0.78, 0.662, 0.343, 0.741, 0.527, 0.741, 0.646], ['TheBloke/vicuna-7B-v1.5-GPTQ', 0.623, 0.573, 0.634, 0.73, 0.662, 0.716, 0.694, 0.695, 0.678, 0.779, 0.678], ['TheBloke/tulu-2-dpo-13B-AWQ', 0.611, 0.583, 0.681, 0.346, 0.667, 0.419, 0.713, 0.709, 0.723, 0.763, 0.621], ['timdettmers/guanaco-7b', 0.567, 0.517, 0.613, 0.664, 0.649, 0.59, 0.695, 0.71, 0.724, 0.738, 0.647], ['TheBloke/guanaco-13B-GPTQ', 0.562, 0.44, 0.513, 0.613, 0.615, 0.507, 0.606, 0.615, 0.646, 0.625, 0.574]]\n",
      "text_model_list [['TheBloke/Orca-2-13B-AWQ', 0.055, 0.171, 0.118, 0.072, 0.079, 0.247, 0.194, 0.156, 0.019, 0.086, 0.12], ['microsoft/Orca-2-7b', 0.043, 0.033, 0.128, 0.097, 0.077, 0.076, 0.057, 0.106, 0.016, 0.204, 0.084], ['01-ai/Yi-6B', 0.022, 0.064, 0.066, 0.009, 0.0, 0.019, 0.042, 0.076, 0.007, 0.032, 0.034], ['WizardLM/WizardLM-13B-V1.1', 0.054, 0.046, 0.083, 0.073, 0.073, 0.026, 0.064, 0.103, 0.007, 0.177, 0.071], ['TheBloke/WizardLM-7B-V1.0-Uncensored-GPTQ', 0.116, 0.054, 0.102, 0.045, 0.194, 0.178, 0.145, 0.131, 0.014, 0.208, 0.119], ['TheBloke/llava-v1.5-13B-AWQ', 0.091, 0.075, 0.171, 0.083, 0.113, 0.043, 0.136, 0.147, 0.004, 0.235, 0.11], ['TheBloke/vicuna-7B-v1.5-GPTQ', 0.086, 0.087, 0.125, 0.134, 0.117, 0.26, 0.126, 0.043, 0.011, 0.189, 0.118], ['TheBloke/tulu-2-dpo-13B-AWQ', 0.058, 0.063, 0.101, 0.071, 0.109, 0.068, 0.112, 0.0, 0.008, 0.199, 0.079], ['timdettmers/guanaco-7b', 0.067, 0.042, 0.151, 0.061, 0.074, 0.22, 0.088, 0.135, 0.01, 0.128, 0.098], ['TheBloke/guanaco-13B-GPTQ', 0.084, 0.09, 0.091, 0.135, 0.061, 0.138, 0.08, 0.072, 0.001, 0.144, 0.09]]\n",
      "qa_model_list [['TheBloke/Orca-2-13B-AWQ', 0.117, 0.027, 0.213, 0.059, 0.054, 0.002, 0.204, 0.277, 0.215, 0.11, 0.128], ['microsoft/Orca-2-7b', 0.108, 0.035, 0.213, 0.053, 0.054, 0.826, 0.004, 0.117, 0.203, 0.07, 0.168], ['01-ai/Yi-6B', 0.053, 0.016, 0.187, 0.086, 0.077, 0.0, 0.156, 0.031, 0.11, 0.059, 0.077], ['WizardLM/WizardLM-13B-V1.1', 0.072, 0.048, 0.115, 0.108, 0.082, 0.452, 0.198, 0.175, 0.207, 0.086, 0.154], ['TheBloke/WizardLM-7B-V1.0-Uncensored-GPTQ', 0.048, 0.064, 0.213, 0.182, 0.109, 0.291, 0.214, 0.214, 0.142, 0.112, 0.159], ['TheBloke/llava-v1.5-13B-AWQ', 0.119, 0.047, 0.213, 0.146, 0.233, 0.119, 0.013, 0.263, 0.041, 0.152, 0.135], ['TheBloke/vicuna-7B-v1.5-GPTQ', 0.065, 0.034, 0.095, 0.174, 0.079, 0.184, 0.21, 0.201, 0.089, 0.199, 0.133], ['TheBloke/tulu-2-dpo-13B-AWQ', 0.067, 0.053, 0.139, 0.0, 0.061, 0.0, 0.207, 0.216, 0.204, 0.17, 0.112], ['timdettmers/guanaco-7b', 0.086, 0.039, 0.064, 0.105, 0.082, 0.03, 0.154, 0.186, 0.22, 0.158, 0.112], ['TheBloke/guanaco-13B-GPTQ', 0.05, 0.021, 0.031, 0.047, 0.066, 0.025, 0.142, 0.089, 0.107, 0.049, 0.063]]\n",
      "text_model_list [['TheBloke/Orca-2-13B-AWQ', 0.537, 0.735, 0.697, 0.599, 0.562, 0.689, 0.768, 0.648, 0.554, 0.657, 0.6446], ['microsoft/Orca-2-7b', 0.561, 0.492, 0.653, 0.645, 0.566, 0.534, 0.622, 0.581, 0.424, 0.724, 0.5802], ['01-ai/Yi-6B', 0.356, 0.624, 0.458, 0.276, 0.326, 0.648, 0.384, 0.493, 0.41, 0.426, 0.4401], ['WizardLM/WizardLM-13B-V1.1', 0.569, 0.591, 0.641, 0.616, 0.558, 0.553, 0.65, 0.644, 0.592, 0.765, 0.6178999999999999], ['TheBloke/WizardLM-7B-V1.0-Uncensored-GPTQ', 0.562, 0.583, 0.667, 0.5, 0.672, 0.687, 0.657, 0.637, 0.54, 0.761, 0.6266], ['TheBloke/llava-v1.5-13B-AWQ', 0.542, 0.602, 0.716, 0.627, 0.572, 0.554, 0.679, 0.641, 0.548, 0.741, 0.6222000000000001], ['TheBloke/vicuna-7B-v1.5-GPTQ', 0.563, 0.618, 0.655, 0.679, 0.589, 0.763, 0.7, 0.597, 0.589, 0.728, 0.6481], ['TheBloke/tulu-2-dpo-13B-AWQ', 0.564, 0.589, 0.687, 0.622, 0.571, 0.599, 0.697, 0.293, 0.542, 0.742, 0.5906], ['timdettmers/guanaco-7b', 0.583, 0.566, 0.693, 0.615, 0.523, 0.731, 0.685, 0.625, 0.565, 0.732, 0.6318], ['TheBloke/guanaco-13B-GPTQ', 0.563, 0.608, 0.629, 0.586, 0.51, 0.629, 0.593, 0.588, 0.423, 0.683, 0.5812]]\n",
      "qa_model_list [['TheBloke/Orca-2-13B-AWQ', 0.634, 0.473, 0.752, 0.623, 0.551, 0.292, 0.699, 0.792, 0.773, 0.703, 0.6292], ['microsoft/Orca-2-7b', 0.635, 0.544, 0.761, 0.608, 0.624, 0.978, 0.387, 0.663, 0.747, 0.634, 0.6581000000000001], ['01-ai/Yi-6B', 0.53, 0.375, 0.713, 0.605, 0.598, 0.418, 0.595, 0.506, 0.488, 0.589, 0.5417], ['WizardLM/WizardLM-13B-V1.1', 0.637, 0.584, 0.652, 0.677, 0.652, 0.923, 0.731, 0.721, 0.736, 0.669, 0.6981999999999999], ['TheBloke/WizardLM-7B-V1.0-Uncensored-GPTQ', 0.653, 0.585, 0.757, 0.733, 0.673, 0.813, 0.699, 0.722, 0.708, 0.704, 0.7047], ['TheBloke/llava-v1.5-13B-AWQ', 0.657, 0.542, 0.738, 0.727, 0.78, 0.662, 0.343, 0.741, 0.527, 0.741, 0.6457999999999999], ['TheBloke/vicuna-7B-v1.5-GPTQ', 0.623, 0.573, 0.634, 0.73, 0.662, 0.716, 0.694, 0.695, 0.678, 0.779, 0.6784], ['TheBloke/tulu-2-dpo-13B-AWQ', 0.611, 0.583, 0.681, 0.346, 0.667, 0.419, 0.713, 0.709, 0.723, 0.763, 0.6214999999999999], ['timdettmers/guanaco-7b', 0.567, 0.517, 0.613, 0.664, 0.649, 0.59, 0.695, 0.71, 0.724, 0.738, 0.6467], ['TheBloke/guanaco-13B-GPTQ', 0.562, 0.44, 0.513, 0.613, 0.615, 0.507, 0.606, 0.615, 0.646, 0.625, 0.5742]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m export_bleu_score()\n\u001b[1;32m      3\u001b[0m export_rouge_score()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mexport_prometheus_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 46\u001b[0m, in \u001b[0;36mexport_prometheus_score\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m model_name \u001b[38;5;241m=\u001b[39m score_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_score\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     45\u001b[0m feedbacks \u001b[38;5;241m=\u001b[39m score_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_score\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeedbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 46\u001b[0m text_score_list, qa_score_list \u001b[38;5;241m=\u001b[39m extract_score(feedbacks)\n\u001b[1;32m     47\u001b[0m text_score_list\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, model_name)\n\u001b[1;32m     48\u001b[0m qa_score_list\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, model_name)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "export_bert_score()\n",
    "export_bleu_score()\n",
    "export_rouge_score()\n",
    "export_prometheus_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3435ed-1b98-4ddd-885e-fe5eee1ff87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_model_list [['TheBloke/Orca-2-13B-AWQ', 0.109, 0.326, 0.301, 0.142, 0.193, 0.364, 0.393, 0.273, 0.163, 0.186, 0.245], ['microsoft/Orca-2-7b', 0.104, 0.147, 0.254, 0.181, 0.183, 0.123, 0.148, 0.225, 0.031, 0.28, 0.168], ['01-ai/Yi-6B', 0.072, 0.129, 0.099, 0.009, 0.0, 0.24, 0.111, 0.206, 0.095, 0.138, 0.11], ['WizardLM/WizardLM-13B-V1.1', 0.126, 0.14, 0.224, 0.141, 0.187, 0.079, 0.158, 0.222, 0.143, 0.276, 0.17], ['TheBloke/WizardLM-7B-V1.0-Uncensored-GPTQ', 0.175, 0.142, 0.239, 0.153, 0.291, 0.311, 0.227, 0.245, 0.15, 0.297, 0.223], ['TheBloke/llava-v1.5-13B-AWQ', 0.14, 0.194, 0.351, 0.153, 0.213, 0.092, 0.283, 0.242, 0.069, 0.352, 0.209], ['TheBloke/vicuna-7B-v1.5-GPTQ', 0.142, 0.176, 0.212, 0.184, 0.201, 0.385, 0.228, 0.142, 0.16, 0.275, 0.21], ['TheBloke/tulu-2-dpo-13B-AWQ', 0.135, 0.181, 0.249, 0.116, 0.191, 0.151, 0.227, 0.0, 0.197, 0.267, 0.171], ['timdettmers/guanaco-7b', 0.156, 0.093, 0.271, 0.134, 0.135, 0.364, 0.197, 0.24, 0.098, 0.191, 0.188], ['TheBloke/guanaco-13B-GPTQ', 0.16, 0.157, 0.2, 0.208, 0.137, 0.237, 0.148, 0.159, 0.103, 0.264, 0.177]]\n",
      "qa_model_list [['TheBloke/Orca-2-13B-AWQ', 0.278, 0.119, 0.37, 0.128, 0.165, 0.007, 0.263, 0.383, 0.241, 0.23, 0.218], ['microsoft/Orca-2-7b', 0.226, 0.081, 0.408, 0.144, 0.137, 0.909, 0.03, 0.193, 0.23, 0.197, 0.256], ['01-ai/Yi-6B', 0.191, 0.08, 0.375, 0.193, 0.174, 0.0, 0.267, 0.13, 0.251, 0.156, 0.182], ['WizardLM/WizardLM-13B-V1.1', 0.216, 0.148, 0.255, 0.195, 0.203, 0.762, 0.27, 0.283, 0.24, 0.195, 0.277], ['TheBloke/WizardLM-7B-V1.0-Uncensored-GPTQ', 0.15, 0.168, 0.408, 0.273, 0.21, 0.606, 0.247, 0.274, 0.132, 0.236, 0.27], ['TheBloke/llava-v1.5-13B-AWQ', 0.275, 0.168, 0.407, 0.267, 0.284, 0.377, 0.01, 0.376, 0.096, 0.319, 0.258], ['TheBloke/vicuna-7B-v1.5-GPTQ', 0.198, 0.103, 0.23, 0.257, 0.198, 0.316, 0.261, 0.262, 0.157, 0.338, 0.232], ['TheBloke/tulu-2-dpo-13B-AWQ', 0.191, 0.137, 0.214, 0.0, 0.182, 0.0, 0.281, 0.308, 0.201, 0.291, 0.18], ['timdettmers/guanaco-7b', 0.182, 0.147, 0.171, 0.206, 0.182, 0.105, 0.227, 0.249, 0.208, 0.291, 0.197], ['TheBloke/guanaco-13B-GPTQ', 0.144, 0.09, 0.103, 0.092, 0.186, 0.062, 0.179, 0.154, 0.157, 0.127, 0.129]]\n"
     ]
    }
   ],
   "source": [
    "export_rouge_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c78ad767-4b80-4037-80ae-410f0dc21b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_last_column(csv_file):\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        last_column_values = [row[-1] for row in reader]\n",
    "        # Remove the header row if it exists\n",
    "        if len(last_column_values) > 0 and last_column_values[0] == 'avg score':\n",
    "            last_column_values.pop(0)\n",
    "        return last_column_values\n",
    "\n",
    "def create_csv(rows_data, file_name):\n",
    "    headers = [\"Model Name / Instruction Number\", \"bleu\", \"bert\", \"rouge\", \"prometheus\"]\n",
    "    with open(file_name, \"w\", newline=\"\") as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(headers)\n",
    "        csv_writer.writerows(rows_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "304a90be-7f7f-4e53-aa84-73f9d5633689",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = read_last_column(\"prometheus_score_tg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afba7d42-357f-436e-aabd-7551039723b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def merge_csv_files(csv_files, new_csv_file):\n",
    "    # Initialize a list to store data rows\n",
    "    data_rows = []\n",
    "\n",
    "    # Read average scores from each CSV file\n",
    "    for file_path in csv_files:\n",
    "        with open(file_path, 'r') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                model_name = row[\"Model Name / Instruction Number\"]\n",
    "                score = float(row[\"avg score\"])\n",
    "                data_rows.append({\"Model Name / Instruction Number\": model_name, file_path.split('_')[0]: score})\n",
    "\n",
    "    # Create a new CSV file with the desired header\n",
    "    #new_csv_file = 'merged_scores.csv'\n",
    "    with open(new_csv_file, 'w', newline='') as file:\n",
    "        fieldnames = [\"Model Name / Instruction Number\", \"bleu\", \"bert\", \"rougeL\", \"prometheus\"]\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Write data rows to the new CSV file\n",
    "        for row in data_rows:\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a7bb1e-46e5-4f09-a4e6-e4170b83b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "csv_files = ['bleu_score_tg.csv', 'bert_score_tg.csv', 'rougeL_score_tg.csv', 'prometheus_score_tg.csv']\n",
    "merge_csv_files(csv_files, 'tg_merged_score.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a57b13-e6ac-425b-954a-23338a415076",
   "metadata": {},
   "source": [
    "## Code to plot graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b7be4e-fe72-4598-b182-9e60ac3b7486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = {\n",
    "    \"Model Name\": [\n",
    "        \"Orca-2-13B\",\n",
    "        \"Orca-2-7b\",\n",
    "        \"Yi-6B\",\n",
    "        \"WizardLM-13B-V1.1\",\n",
    "        \"WizardLM-7B-V1.0\",\n",
    "        \"llava-v1.5-13B\",\n",
    "        \"vicuna-7B-v1.5\",\n",
    "        \"tulu-2-dpo-13B\",\n",
    "        \"guanaco-7b\",\n",
    "        \"guanaco-13B\",\n",
    "    ],\t\n",
    "    \"bleu\": [\n",
    "        0.128,\n",
    "        0.168,\n",
    "        0.77,\n",
    "        0.154,\n",
    "        0.159,\n",
    "        0.135,\n",
    "        0.133,\n",
    "        0.112,\n",
    "        0.112,\n",
    "        0.63,\n",
    "    ],\n",
    "    \"bert\": [\n",
    "        0.629,\n",
    "        0.658,\n",
    "        0.542,\n",
    "        0.698,\n",
    "        0.705,\n",
    "        0.646,\n",
    "        0.678,\n",
    "        0.621,\n",
    "        0.647,\n",
    "        0.574,\n",
    "    ],\n",
    "    \"rougeL\": [\n",
    "        0.218,\n",
    "        0.256,\n",
    "        0.182,\n",
    "        0.277,\n",
    "        0.27,\n",
    "        0.258,\n",
    "        0.232,\n",
    "        0.18,\n",
    "        0.197,\n",
    "        0.129,\n",
    "    ],\n",
    "    \"prometheus\": [3.5, 3.2, 1.8, 4.7, 3.7, 3.2, 3.8, 3.9, 3.0, 2.7],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract scores columns for normalization\n",
    "scores = df[[\"bleu\", \"bert\", \"rougeL\", \"prometheus\"]]\n",
    "\n",
    "# Normalize scores using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "normalized_scores = scaler.fit_transform(scores)\n",
    "# Update the DataFrame with normalized scores\n",
    "#df[[\"bleu\", \"bert\", \"rougeL\", \"prometheus\"]] = normalized_scores\n",
    "\n",
    "# Define custom colors for the bars\n",
    "colors = [\"b\", \"g\", \"r\", \"c\"]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, col in enumerate([\"bleu\", \"bert\", \"rougeL\", \"prometheus\"]):\n",
    "    plt.bar(\n",
    "        df.index + i * 0.2,  # Shift bars for adjacent positioning\n",
    "        df[col],\n",
    "        width=0.2,\n",
    "        label=col,\n",
    "        color=colors[i],\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Model Name\")\n",
    "plt.ylabel(\"Avg. Task Score\")\n",
    "plt.title(\"Model Name Vs. Avg. Task Score\")\n",
    "plt.xticks(df.index, df[\"Model Name\"], rotation=90)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dfe04a-42ed-486f-b25b-c49aa5c82ab6",
   "metadata": {},
   "source": [
    "## Code for pearson analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a1160e-b685-4775-b64a-d0f1463e8f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bleu          0.169099\n",
       "bert          0.806509\n",
       "rougeL        0.612497\n",
       "prometheus    1.000000\n",
       "Name: prometheus, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pearson correlation analysis for tg scores\n",
    "import pandas as pd\n",
    "data = {\n",
    "    'bleu': [0.12, 0.84, 0.34, 0.71, 0.119, 0.11, 0.118, 0.79, 0.98, 0.09],\n",
    "    'bert': [0.645, 0.58, 0.44, 0.618, 0.627, 0.622, 0.648, 0.591, 0.632, 0.581],\n",
    "    'rougeL': [0.245, 0.168, 0.11, 0.17, 0.223, 0.209, 0.21, 0.171, 0.188, 0.177],\n",
    "    'prometheus': [4.3, 3.2, 1.6, 5.0, 4.0, 4.0, 3.5, 4.4, 3.8, 3.2]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate correlation matrix using Pearson method\n",
    "correlation_matrix = df.corr(method='pearson')\n",
    "\n",
    "# Extract Prometheus correlations\n",
    "prometheus_correlations = correlation_matrix['prometheus']\n",
    "prometheus_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4879346d-c168-41b0-94ae-5fb2bab6d139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bleu         -0.762148\n",
       "bert          0.815986\n",
       "rougeL        0.575397\n",
       "prometheus    1.000000\n",
       "Name: prometheus, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pearson correlation analysis for qa scores\n",
    "import pandas as pd\n",
    "data = {\n",
    "    \"bleu\": [\n",
    "        0.128,\n",
    "        0.168,\n",
    "        0.77,\n",
    "        0.154,\n",
    "        0.159,\n",
    "        0.135,\n",
    "        0.133,\n",
    "        0.112,\n",
    "        0.112,\n",
    "        0.63,\n",
    "    ],\n",
    "    \"bert\": [\n",
    "        0.629,\n",
    "        0.658,\n",
    "        0.542,\n",
    "        0.698,\n",
    "        0.705,\n",
    "        0.646,\n",
    "        0.678,\n",
    "        0.621,\n",
    "        0.647,\n",
    "        0.574,\n",
    "    ],\n",
    "    \"rougeL\": [\n",
    "        0.218,\n",
    "        0.256,\n",
    "        0.182,\n",
    "        0.277,\n",
    "        0.27,\n",
    "        0.258,\n",
    "        0.232,\n",
    "        0.18,\n",
    "        0.197,\n",
    "        0.129,\n",
    "    ],\n",
    "    \"prometheus\": [3.5, 3.2, 1.8, 4.7, 3.7, 3.2, 3.8, 3.9, 3.0, 2.7],\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate correlation matrix using Pearson method\n",
    "correlation_matrix = df.corr(method='pearson')\n",
    "\n",
    "# Extract Prometheus correlations\n",
    "prometheus_correlations = correlation_matrix['prometheus']\n",
    "prometheus_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e2fc1-c7b3-4029-a4ae-36298d20db14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
